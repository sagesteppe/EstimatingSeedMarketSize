data <- autofill_checker(data)
data <- coords2sf(data)
# write out KMLs for people to verify that their coordinates are correct.
d_split <- dplyr::group_split(data, !!as.name('Primary_Collector'))
for (i in seq_along(d_split)){
geodata_writer(
d_split[[i]],
filename = gsub(' ', '_', unique(d_split[[i]]$Primary_Collector)),
path = '../kmls')
}
rm(d_split, i)
p2geo <- '/media/steppe/hdd/BL_sandbox/geodata-MI'
# TODO ADD VALLEYS TO POLITICAL GRABBER AS AN OPTION....
data <- political_grabber(data, y = 'UNIQUEID', path = p2geo)
data <- physical_grabber(data, path = p2geo)
data <- site_writer(data, path = p2geo)
p2tax <- '/media/steppe/hdd/BL_sandbox/taxdata-MI'
data <- data |>
unite(Full_name, c('Genus', 'Epithet', 'Infrarank', Infraspecies),
remove = F, na.rm = TRUE, sep = ' ')
data <- drop_na(data, Genus)
dat <- spell_check(data = data, column = 'Full_name', path = p2tax)
data <- family_spell_check(data, path = p2tax)
data <- author_check(data, path = p2tax)
data <- associates_spell_check(data, 'Associates', path = p2tax) # we can run on both columns.
data <- associate_dropper(data, 'Full_name', col  = 'Associates')
data <- associate_dropper(data, 'Full_name', col  = 'Vegetation')
data <- date_parser(data, coll_date = 'Date_digital', det_date = 'Determined_date')
rm(p2geo, p2tax)
View(data)
# honestly just overwrite these too.
data <- data %>%
select(-SpellCk.gGRP, -Match, -SpellCk.taxon_rank,
-Full_name, -Genus, -Epithet, -Infrarank, -Infraspecies) |>
rename(Full_name = SpellCk.taxon_name, Genus = SpellCk.genus, Epithet = SpellCk.species,
Infrarank = SpellCk.infraspecific_rank, Infraspecies = SpellCk.infraspecies)
names <- sf::st_drop_geometry(data) %>%
pull(Full_name)
pow_res <- lapply(names,
powo_searcher) %>%
bind_rows()
pow_res <- lapply(names,
powo_searcher) %>%
bind_rows()
data <- bind_cols(data, pow_res)
rm(names, pow_res)
data <- data %>%
sf::st_as_sf()
View(data)
View(data)
data |>
unite(Habitat, Soil, Soil_Texture, 'Habitat')
View(data)
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat')
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat') |>
select(Habitat)
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat', sep, = ' ') |>
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat', sep = ' ') |>
select(Habitat)
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat1', sep = ' ') |>
select(Habitat)
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat1', sep = ' ') |>
select(Habitat1)
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat1', sep = ' ') |>
select(Habitat1)
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat1', sep = ' ') |>
select(Habitat1)
data |>
unite(Habitat, Soil_Color, Soil_Texture, 'Habitat1', sep = ' ') #|>
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Color, Soil_Texture)
)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Color, Soil_Texture)
) |>
select(Habitat1)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Color, Soil_Texture)
) |>
select(Habitat)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Color, ' ', Soil_Texture)
) |>
select(Habitat)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Color, ', ', Soil_Texture)
) |>
select(Habitat)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color, )
) |>
select(Habitat)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color )
) |>
select(Habitat)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color )
)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color ),
Determined_by = str_remove(Determined_by, ',.*')
)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color ),
Determined_by = str_remove(Determined_by, ',.*'),
Fide = str_replace(Fide, 'with USDA PLANTS database nomenclature', '(USDA PLANTS nomenclature')
)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color ),
Determined_by = str_remove(Determined_by, ',.*'),
Fide = str_replace(Fide, 'with USDA PLANTS database nomenclature', '(USDA PLANTS nomenclature)')
)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color ),
Determined_by = str_remove(Determined_by, ',.*'),
Fide = str_replace(Fide, ', with USDA PLANTS database nomenclature', ' (USDA PLANTS nomenclature)')
)
data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color ),
Determined_by = str_remove(Determined_by, ',.*'),
Fide = str_replace(Fide, ', with USDA PLANTS database nomenclature', ' (USDA PLANTS nomenclature)'),
Aspect = Slope
)
# devtools::install_github('sagesteppe/BarnebyLives', force = TRUE)
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
library(textclean)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
mi <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number)) %>%
data.frame() |>
drop_na(Primary_Collector)
data <- mi
data <- dms2dd(data)
# devtools::install_github('sagesteppe/BarnebyLives', force = TRUE)
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
library(textclean)
googledrive::drive_auth("reedbenkendorf27@gmail.com")
# read in data from the sheet to process
mi <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Data Entry Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number)) %>%
data.frame() |>
drop_na(Primary_Collector)
data <- mi
data <- dms2dd(data)
data <- autofill_checker(data)
data <- coords2sf(data)
# write out KMLs for people to verify that their coordinates are correct.
d_split <- dplyr::group_split(data, !!as.name('Primary_Collector'))
for (i in seq_along(d_split)){
geodata_writer(
d_split[[i]],
filename = gsub(' ', '_', unique(d_split[[i]]$Primary_Collector)),
path = '../kmls')
}
rm(d_split, i)
p2geo <- '/media/steppe/hdd/BL_sandbox/geodata-MI'
# TODO ADD VALLEYS TO POLITICAL GRABBER AS AN OPTION....
data <- political_grabber(data, y = 'UNIQUEID', path = p2geo)
data <- physical_grabber(data, path = p2geo)
data <- site_writer(data, path = p2geo)
p2tax <- '/media/steppe/hdd/BL_sandbox/taxdata-MI'
data <- data |>
unite(Full_name, c('Genus', 'Epithet', 'Infrarank', Infraspecies),
remove = F, na.rm = TRUE, sep = ' ')
data <- drop_na(data, Genus)
dat <- spell_check(data = data, column = 'Full_name', path = p2tax)
data <- family_spell_check(data, path = p2tax)
data <- author_check(data, path = p2tax)
data <- associates_spell_check(data, 'Associates', path = p2tax) # we can run on both columns.
data <- associate_dropper(data, 'Full_name', col  = 'Associates')
data <- associate_dropper(data, 'Full_name', col  = 'Vegetation')
data <- date_parser(data, coll_date = 'Date_digital', det_date = 'Determined_date')
rm(p2geo, p2tax)
names <- sf::st_drop_geometry(data) %>%
pull(Full_name)
pow_res <- lapply(names,
powo_searcher) %>%
bind_rows()
pow_res <- lapply(names,
powo_searcher) %>%
bind_rows()
data <- bind_cols(data, pow_res)
rm(names, pow_res)
data <- data %>%
sf::st_as_sf()
data <- data |>
mutate(
Habitat = paste0(Habitat, '; Soil: ', Soil_Texture, ', ', Soil_Color ),
Determined_by = str_remove(Determined_by, ',.*'),
Fide = str_replace(Fide, ', with USDA PLANTS database nomenclature', ' (USDA PLANTS nomenclature)'),
Aspect = aspect
)
# first ensure the columns are in the same order as google sheets
processed_cols <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed - Examples') %>%
colnames()
df <- data %>%
sf::st_drop_geometry() %>%
relocate(any_of(processed_cols)) %>%
arrange(Primary_Collector, Collection_number)
df |>
write_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024')
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
p2libs <- .libPaths()[
grepl(paste0(version$major, '.', sub('\\..*', "", version$minor)),
.libPaths())]
folds <- c('BarnebyLives/rmarkdown/templates/labels/skeleton/skeleton.Rmd')
file.copy(from = file.path(p2libs, folds), '.')
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
purrr::walk(
.x = proc_split[['Liz Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Liz.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
View(processed)
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
proc_split[['Elizabeth Haber']]$Collection_number
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Liz.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
dir.create('../HerbariumLabels/raw')
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
View(processed)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(BarnebyLives)
data <- read.csv('../results/collections-Elizabeth_Haber.csv') |>
dplyr::filter(Collection_number == params$Collection_number) |>
sf::st_drop_geometry()
library(tidyverse)
library(BarnebyLives)
library(googlesheets4)
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
dir.create('../HerbariumLabels/raw')
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
dir.create('../HerbariumLabels/raw')
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
View(proc_split)
dir.create('../HerbariumLabels/raw/Genevieve-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Genevieve-raw'
dir.create('../HerbariumLabels/raw/Genevieve-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Genevieve-raw'
purrr::walk(
.x = proc_split[['Genevieve Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Genevieve.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
purrr::walk(
.x = proc_split[['Genevieve Nutter']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Genevieve.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
processed <- read_sheet('1iOQBNeGqRJ3yhA-Sujas3xZ2Aw5rFkktUKv3N_e4o8M',
sheet = 'Processed Michigan - 2024') %>%
mutate(UNIQUEID = paste0(Primary_Collector, Collection_number),
Coordinate_Uncertainty = '+/- 5m') %>%
# select(-Directions_BL) %>%
data.frame()
processed <- data.frame( apply(processed, 2, as.character) )
processed <- mutate(processed, Collection_number = as.numeric(Collection_number))
proc_split <- split(processed, processed$Primary_Collector)
fnames <- paste0('../results/collections-', gsub(' ', '_', names(proc_split)), '.csv')
for(i in 1:length(proc_split)) {
write.csv(proc_split[[i]], fnames[i], row.names = F)
}
dir.create('../HerbariumLabels/raw/Elizabeth-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Elizabeth-raw'
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
purrr::walk(
.x = proc_split[['Elizabeth Haber']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Elizabeth.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
dir.create('../HerbariumLabels/raw/Genevieve-raw')
p <- '/media/steppe/hdd/2024SOS_HerbariumSpecimens/HerbariumLabels/raw/Genevieve-raw'
purrr::walk(
.x = proc_split[['Genevieve Nutter']]$Collection_number,
~ rmarkdown::render(
input = 'skeleton-Genevieve.Rmd',
output_file = file.path(p, glue::glue("{.x}.pdf")),
params = list(Collection_number = {.x})
)
)
install.packages('fasterize')
?fasterize
library(fasterize)
?fasterize
doi_conus <- fasterize::fasterize(doi, conus, field = 'Mang_Name', fun = 'any')
doi <- filter(padus, Mang_Name %in% c('BLM', 'FWS', 'NPS', 'USBR', 'BIA'))
p <- file.path('..', 'data', 'geospatial', 'PADUS4_0Geodatabase', 'PADUS4_0_Geodatabase.gdb')
padus <- sf::st_read(
dsn = p, quiet = TRUE,
layer = 'PADUS4_0Fee')  |>
dplyr::select(Mang_Name, Mang_Type, Loc_Mang, Unit_Nm, IUCN_Cat)  |>
sf::st_cast('MULTIPOLYGON')
padus <- sf::st_read(
dsn = p, quiet = TRUE,
layer = 'PADUS4_0Fee')  |>
dplyr::select(Mang_Name, Mang_Type, Loc_Mang, Unit_Nm, IUCN_Cat)  |>
sf::st_cast('MULTIPOLYGON')
doi <- filter(padus, Mang_Name %in% c('BLM', 'FWS', 'NPS', 'USBR', 'BIA'))
library(terra)
library(tidyverse)
sp <- file.path('..', 'data', 'geospatial', 'NLCD')
temp1 <- rast('/media/steppe/hdd/SeedMarketSizeTemplates/NorthAmerica_NLCD-CONUS-PR.tif')
ak <- rast(file.path(sp, 'NLCD_2016_Land_Cover_AK_20200724', 'AK_NLCD-WGS84.tif'))
ak <- resample(ak, temp, method = 'mode', threads = TRUE)
ak <- resample(ak, temp1, method = 'mode', threads = TRUE)
ak <- resample(ak, temp1, method = 'mode', threads = TRUE)
