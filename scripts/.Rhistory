```{r Object Types - SpatialPolygonsDataFrame 1,echo = TRUE}
writeLines(s3_class(dec_lakes_sp))
s3_class(dec_lakes_sp)
str(dec_lakes_sp, max.level = 1)
dec_lakes_sp@plotOrder
otype(dec_lakes_sp@plotOrder)
lapply(dec_lakes_sp, otype)
lapply(dec_lakes_sp, otype)
apply(dec_lakes_sp, otype)
dec_lakes_sp
lapply(dec_lakes_sp, otype)
str(dec_lakes_sp, max.level = 1)
lapply(dec_lakes_sp, otype)
otype(dec_lakes_sp@data)
slot(dec_lakes_sp,data)
slot(dec_lakes_sp,'data')
slot(dec_lakes_sp)
slots(dec_lakes_sp)
str(dec_lakes_sp, max.level = 1)
str(dec_lakes_sp, max.level = 2)
out <- str(dec_lakes_sp, max.level = 2)
str(dec_lakes_sp, max.level = 2)
slotNames(dec_lakes_sp)
sN <- slotNames(dec_lakes_sp)
slot(dec_lakes_sp, sN)
slot(dec_lakes_sp, sN[1])
slot(dec_lakes_sp, 1)
otype(slot(dec_lakes_sp, sN[1]))
otype(slot(dec_lakes_sp, sN[1]))
sN <- slotNames(dec_lakes_sp)
S4check <- function(x, sN){
otype(slot(dec_lakes_sp, sN[1]))
}
for (i in seq_along(sN)){
otype(slot(dec_lakes_sp, sN[i]))
}
sN <- slotNames(dec_lakes_sp)
for (i in seq_along(sN)){
otype(slot(dec_lakes_sp, sN[i]))
}
print(otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
print(otype(slot(dec_lakes_sp, sN[i])))
}
writeLines(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
writeLines(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
for (i in seq_along(sN)){
writeLines(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
writeLines(s3_class(dec_lakes_sp@plotOrder))
for (i in seq_along(sN)){
writeLines(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
message(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
message(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
sN <- slotNames(dec_lakes_sp)
for (i in seq_along(sN)){
message(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
sN[i]
sN <- slotNames(dec_lakes_sp)
for (i in seq_along(sN)){
message( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
}
for (i in seq_along(sN)){
message( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
}
for (i in seq_along(sN)){
message( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
}
print( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
for (i in seq_along(sN)){
print( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
}
str(dec_lakes_sp, max.level = 2)
sN <- slotNames(dec_lakes_sp)
for (i in seq_along(sN)){
print( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
}
sN <- slotNames(dec_lakes_sp)
for (i in seq_along(sN)){
message( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
}
for (i in seq_along(sN)){
message( sN[i])
}
for (i in seq_along(sN)){
message( sN[i])
}
for (i in seq_along(sN)){
print( sN[i])
}
for (i in seq_along(sN)){
print( sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])) )
}
paste0( sN[i], ' ', otype(slot(dec_lakes_sp, sN[i])) )
for (i in seq_along(sN)){
paste0( sN[i], ' ', otype(slot(dec_lakes_sp, sN[i])) )
}
for (i in seq_along(sN)){
paste0( sN[i], ' ', otype(slot(dec_lakes_sp, sN[i])) )
}
sN <- slotNames(dec_lakes_sp)
for (i in seq_along(sN)){
paste0( sN[i], ' ', otype(slot(dec_lakes_sp, sN[i])) )
}
for (i in seq_along(sN)){
otype(slot(dec_lakes_sp, sN[i]))
}
for (i in seq_along(sN)){
otype(slot(dec_lakes_sp, sN[i]))
}
seq_along(sN)
print(otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
print(otype(slot(dec_lakes_sp, sN[i])))
}
View(dec_lakes_sp)
for (i in seq_along(sN)){
writeLines(otype(slot(dec_lakes_sp, sN[i])))
}
for (i in seq_along(sN)){
writeLines(sN[i], otype(slot(dec_lakes_sp, sN[i])))
}
?writeLines
for (i in seq_along(sN)){
cat(sN[i], otype(slot(dec_lakes_sp, sN[i])))
}
for (i in seq_along(sN)){
cat(sN[i], ' :' otype(slot(dec_lakes_sp, sN[i])))
cat(sN[i], ' :', otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
cat(sN[i], ' :', otype(slot(dec_lakes_sp, sN[i])))
}
cat(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
cat(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
for (i in seq_along(sN)){
message(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
cat(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
cat(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
paste0(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
for (i in seq_along(sN)){
paste0(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i])))
}
for (i in seq_along(sN)){
print(paste0(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i]))))
}
for (i in seq_along(sN)){
writeLines(paste0(sN[i], ': ', otype(slot(dec_lakes_sp, sN[i]))))
}
slot(dec_lakes_sp, 'polygons')
slot(dec_lakes_sp, 'polygons')[[1]]
otype( slot(dec_lakes_sp, 'polygons')[[1]] )
slotNames(dec_lakes_sp)
slotNames(dec_lakes_sp@polygons)
slot(dec_lakes_sp, 'polygons')
otype(slot(dec_lakes_sp, 'polygons')[[9]])
attributes(slot(dec_lakes_sp, 'polygons')[[9]])
dec_lakes_sp@polygons
slot(dec_lakes_sp, 'polygons') == dec_lakes_sp@polygons
slot(dec_lakes_sp, 'data')
str(example_raster_dec)
slotNames(example_raster_dec)
writeLines(paste0('Class: ', otype(example_raster_dec)))
writeLines(paste0('Class type: ', s3_class(example_raster_dec)))
writeLines(s3_class(example_raster_dec@data))
# attributes(example_raster_dec@data)
writeLines(s3_class(example_raster_dec@data@values))
course_fail <- course(
"Lecture",
'Z', # THIS IS NOT DEFINED
213, 'TH', '2:00-3:50')
s4_ob_office_hours <- new("Office_Hours",
Instructor = c('Benkendorf','Scholl','Benkendorf','Scholl'),
Wing = c('F', 'F', 'G', 'B'),
Number = c(380, 380, 278, 138),
Days = c("M", "W", 'T', 'F'),
Time = c(8, 11, 9, 3),
Smartroom = c(TRUE, F, T, F),
Windows = c(FALSE, T, T, F)
)
course_fail <- course(
name = "Lecture",
wing = 'Z', # THIS IS NOT DEFINED
room = 213,
day = 'TH',
time = '2:00-3:50')
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, comment = "", fig.align="center")
shhh <- suppressPackageStartupMessages
shhh(library(sp))
shhh(library(sf))
shhh(library(raster))
shhh(library(tidyverse))
shhh(library(terra))
shhh(library(sloop)) # for objects
rm(shhh)
# getwd()
path <- file.path('..', 'spatial_lecture_data', 'sentinel_imagery')
files.shp <- list.files(path, ".shp")
dec_lakes_v <- read_sf(file.path(path, files.shp), quiet = T) %>%
mutate(Data_source = 'Sentinel2') %>%
mutate(Processing = 'DL from Earth Explorer, manually georeferenced, and mapped') %>%
mutate(Date = as.POSIXct('2021/12/05', '%Y/%m/%d', tz = "US/Pacific-New"))
st_precision(dec_lakes_v) <- 50 # note I am saying each of the points I drew were within 50 meters of the true location. This is not important but I populate for an example below. We are in meters because we are in UTM.
rm(files.shp)
files.tif <- list.files(path, ".tif")
dec_lakes_r <- raster(file.path(path, files.tif[1]))
oct_lakes_r <- raster(file.path(path, files.tif[3]))
rm(files.tif, path)
reclass_first <- matrix(
c(0, 1, NA,
1 ,50, 0,
50, 250, 1),
nrow = 3,
ncol = 3,
byrow = T)
dec_lakes_r_classified_c <- reclassify(dec_lakes_r, reclass_first)
oct_lakes_r_classified_c <- reclassify(oct_lakes_r, reclass_first)
dec_lakes_r_classified_f <- aggregate(dec_lakes_r_classified_c, 7.0)
oct_lakes_r_classified_f <- aggregate(oct_lakes_r_classified_c, 7.0)
reclass_second <- matrix(
c(0, 0.5, 0,
0.5, 1, 1),
nrow = 2,
ncol = 3,
byrow = T)
dec_lakes_r_classified_f <- reclassify(dec_lakes_r_classified_f, reclass_second)
oct_lakes_r_classified_f <- reclassify(oct_lakes_r_classified_f, reclass_second)
rm(reclass_first, reclass_second, dec_lakes_r_classified_c, oct_lakes_r_classified_c, oct_lakes_r)
ext_rast <- st_bbox(dec_lakes_r)
grid <- st_make_grid(ext_rast,  # create a fishnet to emulate the idea of an empty raster ! :-)
n = c(118, 118),
what = "polygons",
square = TRUE,
flat_topped = FALSE)
# st_write(grid, 'Example_HoneyLake_Grid.shp')
empty_raster <- raster(
# A raster is composed of four perpendicular lines.
# Here we define each 'edge' of the raster'
xmn = 697129.7,
xmx = 811775.7,
ymn = 4388466,
ymx = 4502382,
nrows = 118, # we are creating 100 cells.
ncols = 118, # We can calculate the resolution of these below.
crs = "+proj=utm +zone=10 +datum=WGS84",
# set the rasters Coordinate Reference System
)
rast_vals_num <- as.integer(as.vector(as.numeric(dec_lakes_r_classified_f@data@values)))
raster_matrix <- matrix(rast_vals_num, # fill matrix with values,
nrow = empty_raster@nrows, # create matrix same dimensions as raster
ncol = empty_raster@ncols, # create matrix same dimensions as raster
byrow = T) #ensure filling of matrix goes from upper left to lower right.
example_raster_dec <- setValues(empty_raster, raster_matrix)
example_raster_oct <- setValues(empty_raster, oct_lakes_r_classified_f@data@values )
fake_data <- matrix(c(0,1,1,0,1,0),
nrow = 6,
ncol = 8,
byrow=T)
rm(fake_data, ext_rast, grid)
rast_vals_char <- as.vector(as.character(dec_lakes_r_classified_f@data@values))
rast_vals_char <- ifelse(rast_vals_char == 0, 'Water', 'Terrestrial')
raster_dataframe <- as.data.frame(raster_matrix)
colnames(raster_dataframe) <- c(1:ncol(raster_dataframe))
dec_lakes_sf <- dec_lakes_v |>
relocate(geometry, .after = 6 )
dec_lakes_sp <- as(dec_lakes_v, 'Spatial')
dates_of_imaging <- dec_lakes_sf$Date
rm(dec_lakes_v)
char_v <- c('Apple', 'Orange', 'Banana')
num_v <- 1:3
raster_matrix <- matrix(sample(0:1, size = 9, replace = TRUE), ncol = 3)
raster_pieces_list <- list(
Vector = char_v,
Matrix = raster_matrix,
Dataframe = setNames(LETTERS[1:3], data.frame(raster_matrix))
)
char_v
otype(char_v)
s3_class(char_v)
num_v
otype(num_v)
s3_class(num_v)
raster_matrix
otype(raster_matrix)
s3_class(raster_matrix)
s3_class(raster_pieces_list)
otype(raster_pieces_list)
rm(raster_pieces_list, rast_vals_char, raster_matrix)
junk <- c(1, 999, '9')
s3_class(junk)
rm(junk)
dates_of_imaging[1]
is.character(dates_of_imaging[1])
is.numeric(dates_of_imaging[1])
attributes(dates_of_imaging)
writeLines(paste0("The amount of seconds between 1970 and ", dates_of_imaging[1], " is: ", as.numeric(dates_of_imaging[1])))
as.numeric(dates_of_imaging[1])
otype(dates_of_imaging)
rm(dates_of_imaging)
dstnce <- units::set_units(1.42, meter)
print(dstnce)
units(dstnce) <- units::make_units(yards)
print(dstnce)
writeLines(paste0('A Units is an object of type: ', otype(dstnce)))
writeLines(paste0('It is its own units class: ', s3_class(dstnce)))
attributes(dstnce)
speed <- units::set_units(1.42, m/s)
attributes(speed)
rm(speed, dstnce)
raster_dataframe <- raster_dataframe[1:10, 1:10]
colnames(raster_dataframe) <- sample(letters[1:11], size = ncol(raster_dataframe))
rownames(raster_dataframe) <- sample(LETTERS[14:26], size = nrow(raster_dataframe))
otype(raster_dataframe)
attributes(raster_dataframe)
rm(raster_dataframe)
writeLines(paste0('A simple feature is an object of type: ', otype(dec_lakes_sf)))
knitr::kable(head(iris))
iris <- nest(iris, petal = starts_with("Petal"),
sepal = starts_with("Sepal"))
head(iris)
head(iris[[2]][[1]]) # see 1st row 2nd column
str(iris$petal[[1]]) # structure of 1st row of petal column
s3_class(dec_lakes_sf)
head(dec_lakes_sf[,c(2:3,6)])
attributes(dec_lakes_sf$geometry)
rm(iris, dec_lakes_sf)
otype(dec_lakes_sp)
s3_class(dec_lakes_sp)
str(dec_lakes_sp, max.level = 2)
#| code-line-numbers: "4,8"
sN <- slotNames(dec_lakes_sp)
for (i in seq_along(sN)){
print(paste0(sN[i], ': ',
otype(slot(dec_lakes_sp, sN[i])
)))
}
otype(slot(dec_lakes_sp, 'polygons')[[1]])
head(slot(dec_lakes_sp, 'data'))[,c(2:3,5)]
attributes(slot(dec_lakes_sp, 'data'))
otype(slot(dec_lakes_sp, 'data'))
writeLines(s3_class(slot(dec_lakes_sp, 'data')))
s3_class(slot(dec_lakes_sp, 'proj4string'))
otype(slot(dec_lakes_sp, 'proj4string'))
attributes(slot(dec_lakes_sp, 'proj4string'))
otype(slot(dec_lakes_sp, 'polygons')[[9]])
attributes(slot(dec_lakes_sp, 'polygons')[[9]])
rm(dec_lakes_sp)
slotNames(example_raster_dec)
writeLines(paste0('Class: ', otype(example_raster_dec)))
writeLines(paste0('Class type: ', s3_class(example_raster_dec)))
writeLines(s3_class(example_raster_dec@data))
# attributes(example_raster_dec@data)
writeLines(s3_class(example_raster_dec@data@values))
rm(rast_vals_num, example_raster_dec)
course <- list(
name = c("Lecture", "Lecture", "Laboratory", "Laboratory"),
wing = c('L', 'L','M','L'),
room = c(170, 170, 166, 62),
day  = c('T', 'TH', 'F', 'F'),
time = c('3:30-4:50', '3:30-4:50', '12:00-12:50', '2:00-3:50')
)
# we have only made a list so far
s3_class(course)
otype(course)
class(course) <- "Class_times"
# by setting a class attribute we have
# created an S3 object
s3_class(course)
otype(course)
rm(course)
course <- function(n, w, r, d, t){
values <- list(
name = n,
wing = w,
room = r,
day = d,
time = t)
'%notin%' <- Negate('%in%')
type <- c('Lecture', 'Laboratory', 'Seminar')
tech_letters <- LETTERS[1:13]
days <- c('M', 'T', 'W', 'TH', 'F', 'S', 'SU')
if(any(w %notin% tech_letters))
stop("This wing is not valid")
if(any(d %notin% days))
stop("This day is not valid")
if(any(n %notin% type))
stop("This course type is not valid")
attr(values, "class") <- "Course"
return(values)
}
course_success <- course(
c("Lecture", "Lecture", "Laboratory", "Laboratory"),
c('L', 'L','M','L'),
c(170,170,166,62),
c('T','TH','F','F'),
c('3:30-4:50','3:30-4:50', '12:00-12:50', '2:00-3:50')
)
course_fail <- course(
name = "Lecture",
wing = 'Z', # THIS IS NOT DEFINED
room = 213,
day = 'TH',
time = '2:00-3:50')
course_fail <- course(
"Lecture",
'Z', # THIS IS NOT DEFINED
213,
'TH',
'time' = '2:00-3:50')
course_fail <- course(
"Lecture",
'Z', # THIS IS NOT DEFINED
213,
'TH',
'2:00-3:50')
setwd('~/Documents/assoRted/EstimatingSeedMarketSize/scripts')
library(terra)
library(tidyverse)
library(sf)
## Import all years fire perimeters ##
p2dat <- file.path('..', 'data', 'geospatial', 'FirePerimeters')
fire_perim <- st_read(
file.path(p2dat, list.files(p2dat, pattern = 'shp$')), quiet = TRUE) |>
mutate(FIRE_YEAR = as.numeric(FIRE_YEAR)) |>
filter(FIRE_YEAR >= 1990) |> # we are mostly interested in the trend since 95, but some few year
# rolling averages may be worth having.
filter(
FEATURE_CA == 'Wildfire Final Fire Perimeter', FIRE_YEAR != 9999) |>
select(OBJECTID, FIRE_YEAR, INCIDENT) |>
st_transform(4326) |> # was in pseudo-mercator !!! no no
st_make_valid()
## Join the relevant DOI region to the fire
p2dat <- file.path('..', 'data', 'geospatial', 'DOIRegions')
regions <- st_read(
file.path(p2dat, list.files(p2dat, pattern = 'shp$')), quiet = TRUE) |>
select(REG_NAME) |>
sf::st_transform(st_crs(fire_perim))
# this join will split the fires so that they snap to region, this means that
# summary statistic, such as burned area will be based on the region rather than
# the fire.
fire_perim <- st_join(fire_perim, regions, join = st_intersects) |>
drop_na()
# now we can calculate the areas burned by each fire.
areas <- units::set_units(st_area(fire_perim), value = 'acre')
fire_perim <- mutate(fire_perim, Area = areas, .before = geometry)
rm(areas, regions)
# we want to save our cleaned up fire_perimeters, the original had those issues which
# made it unsatisfactory for analysis.
p2dat <- file.path('..', 'data', 'geospatial', 'FirePerimeters', 'Cleaned',
'InterAgencyFirePerimeterHistory_All_Years_View.shp')
st_write(fire_perim, p2dat, append = FALSE)
## we can calculate a variety of summaries as follows:
fire_perim <- group_by(fire_perim, REG_NAME, FIRE_YEAR) |>
sf::st_drop_geometry()
firesYear <- fire_perim %>%
summarise(
NoFire = n(),
TotalArea_Acre = sum(Area)
) |>
drop_na() # three fires in tiny small wonky areas - fractions of an acre.
# note that if a place is missing fire in a year, we need to impute that as an explicit '0'.
# in the firesYear data set.
fire_abs <- expand.grid(
REG_NAME = unique(firesYear$REG_NAME),
FIRE_YEAR = 1990:2023, NoFire = 0, TotalArea_Acre = 0)
# anti join will identify rows in X which are not matched in Y, if all rows in X have matches in Y
# then the anti join will produce an empty tibble as seen here.
anti_join(firesYear, fire_abs, by  = c('REG_NAME' = 'REG_NAME', 'FIRE_YEAR' = 'FIRE_YEAR'))
# write this out as a CSV
# 'NoFires-TotalArea_byDOIRegion.csv'
firesYear <- arrange(firesYear, REG_NAME, FIRE_YEAR)
write.csv(firesYear, file.path('..', 'data', 'processed', 'NoFires-TotalArea_byDOIRegion.csv'), row.names = F)
# we will also write out the raw Fire areas
# 'FireSizes.csv'
fire_perim <- arrange(fire_perim, REG_NAME, FIRE_YEAR)
write.csv(fire_perim, file.path('..', 'data', 'processed', 'FireSizes.csv'), row.names = F)
rm(p2dat, fire_perim, firesYear)
firesYear <- read.csv(file.path('..', 'data', 'processed', 'NoFires-TotalArea_byDOIRegion.csv'))
# note that if a place is missing fire in a year, we need to impute that as an explicit '0'.
ggplot(data = firesYear, aes(x = NoFire)) +
geom_histogram() +
facet_wrap(~REG_NAME)
fire_perim <- read.csv(file.path('..', 'data', 'processed', 'FireSizes.csv'))
# vastly underestimated the skew of the fire sizes, There are MANY very small fires
# there are relatively few large fires.
ggplot(data = fire_perim, aes(x = Area)) +
geom_density() +
facet_wrap(~REG_NAME, scales = 'free')
# note that if a place is missing fire in a year, we need to impute that as an explicit '0'.
ggplot(data = firesYear, aes(x = NoFire)) +
geom_density() +
facet_wrap(~REG_NAME)
# note that if a place is missing fire in a year, we need to impute that as an explicit '0'.
ggplot(data = firesYear, aes(x = NoFire)) +
geom_density() +
facet_wrap(~REG_NAME, scales = 'free')
fire_perim <- read.csv(file.path('..', 'data', 'processed', 'FireSizes.csv'))
# vastly underestimated the skew of the fire sizes, There are MANY very small fires
# there are relatively few large fires.
ggplot(data = fire_perim, aes(x = Area)) +
geom_density() +
facet_wrap(~REG_NAME, scales = 'free')
